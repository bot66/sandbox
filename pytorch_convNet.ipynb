{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minist dataset: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(\"./data/\", train=True, download=True) #60000\n",
    "test= MNIST(\"./data/\",train=False, download=True) #10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  2\n",
      "size:  (28, 28)\n",
      "max pixle value:  255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show random train sample\n",
    "num = np.random.randint(len(train))\n",
    "\n",
    "plt.imshow(train[num][0], cmap='gray')\n",
    "print(\"label: \", train[num][1])\n",
    "\n",
    "print(\"size: \", train[num][0].size)\n",
    "\n",
    "print(\"max pixle value: \", np.max(train[num][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define net\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "    \n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        # forward process\n",
    "#         print(\"input shape: \", x.shape)\n",
    "        x = self.conv1(x)\n",
    "#         print(\"conv1 output shape: \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "#         print(\"conv2 output shape: \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "#         print(\"max_pool2d output shape: \", x.shape)\n",
    "        # checking\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x,1)\n",
    "#         print(\"flatten output shape: \", x.shape)\n",
    "        x = self.fc1(x)\n",
    "#         print(\"fc1 output shape: \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "#         print(\"fc2 output shape: \", x.shape)\n",
    "        \n",
    "        output  = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = torch.rand((1, 1, 28, 28))\n",
    "\n",
    "net = Net()\n",
    "result = net(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### param of Conv2d\n",
    "(height, width)\n",
    "* stride： 卷积核移动步长\n",
    "* padding： padding size\n",
    "* dilation: 感受野散开程度 （[可视化](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)）\n",
    "* groups: 分组卷积 ([Blog](https://www.cnblogs.com/shine-lee/p/10243114.html))\n",
    "* padding_mode: padding模式([Blog](https://blog.csdn.net/hyk_1996/article/details/94447302))\n",
    "\n",
    "### param of MaxPool2d\n",
    "(height, width)\n",
    "* stride： 卷积核移动步长, 默认None, 即和kernel_size相同\n",
    "* padding： padding size\n",
    "* dilation: 感受野散开程度 （[可视化](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)）\n",
    "\n",
    "卷积/池化输出尺寸:\n",
    "```python\n",
    "import math\n",
    "\n",
    "in_w, in_h =28, 28\n",
    "\n",
    "pad_h, pad_w = 0, 0\n",
    "dil_h, dil_w = 1, 1 # default is 1\n",
    "s_h, s_w = 1, 1 # default is 0\n",
    "k_h, k_w = 3, 3\n",
    "\n",
    "#output featuremap size height\n",
    "out_h = math.floor( (in_h + 2*pad_h - dil_h*(k_h-1) - 1)/s_h + 1)\n",
    "#output featuremap size width\n",
    "out_w = math.floor( (in_w + 2*pad_w - dil_w*(k_w-1) - 1)/s_w + 1)\n",
    "print(out_h)\n",
    "print(out_w)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimize function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader\n",
    "# since we are using MNIST from torchvision, no need for \"class Dataset()\"\n",
    "\n",
    "# transforms\n",
    "\n",
    "#PIL Image Transform\n",
    "class Rescale():\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple)),\"output_size not int or tuple\"\n",
    "        self.output_size = output_size\n",
    "    def __call__(self, sample):\n",
    "        image = sample\n",
    "        if isinstance(self.output_size, int):\n",
    "            new_h = new_w = self.output_size\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        image = image.resize((new_w, new_h))\n",
    "\n",
    "        return image\n",
    "\n",
    "class Normalize():\n",
    "    def __init__(self, max_pixle):\n",
    "        self.max_pixle = max_pixle\n",
    "    def __call__(self, sample):\n",
    "        image = sample\n",
    "        image = np.array(image)/self.max_pixle\n",
    "        \n",
    "        return image\n",
    "class ToTensor():\n",
    "    def __call__(self, sample):\n",
    "        image = sample\n",
    "        image = np.expand_dims(image,2)\n",
    "        # H,W,C ==> C,H,W\n",
    "        image = image.transpose((2,0,1))\n",
    "        \n",
    "        image = torch.from_numpy(image).type(torch.FloatTensor)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "# Label Transform\n",
    "class LabelTransform():\n",
    "    def __call__(self, label):\n",
    "        label_arr = np.zeros(10, dtype=int)\n",
    "        label_arr[label] = 1\n",
    "        label = torch.from_numpy(label_arr)\n",
    "        return label\n",
    "\n",
    "# dataloader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "compose = transforms.Compose([Rescale(28),Normalize(255),ToTensor()])\n",
    "\n",
    "train = MNIST(\"./data/\", train=True, \\\n",
    "              download=True, transform=compose, \\\n",
    "             # target_transform=LabelTransform()\\\n",
    "             ) \n",
    "test = MNIST(\"./data/\", train=False, \\\n",
    "              download=True, transform=compose, \\\n",
    "            #  target_transform=LabelTransform()\\\n",
    "            ) \n",
    "trainloader = DataLoader(train, batch_size = 8, shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(test, batch_size = 8, shuffle =True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.755\n",
      "[1,  4000] loss: 0.360\n",
      "[1,  6000] loss: 0.256\n",
      "[2,  2000] loss: 0.174\n",
      "[2,  4000] loss: 0.149\n",
      "[2,  6000] loss: 0.133\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.to(device)\n",
    "#         labels = labels.type(torch.FloatTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs.shape)\n",
    "#         print(labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './pytorch_convNet.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  2\n",
      "size:  (28, 28)\n",
      "max pixle value:  255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = MNIST(\"./data/\", train=True, download=True) #60000\n",
    "test= MNIST(\"./data/\",train=False, download=True) #10000\n",
    "\n",
    "# show random train sample\n",
    "\n",
    "plt.imshow(test[500][0], cmap='gray')\n",
    "print(\"label: \", train[num][1])\n",
    "\n",
    "print(\"size: \", train[num][0].size)\n",
    "\n",
    "print(\"max pixle value: \", np.max(train[num][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = compose(test[500][0]).unsqueeze(0).to(device)\n",
    "ouputs = net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred = torch.max(ouputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0003], device='cuda:0', grad_fn=<MaxBackward0>) tensor([3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(_,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
